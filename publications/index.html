<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Julie R. Pivin-Bachler </title> <meta name="author" content="Julie R. Pivin-Bachler"> <meta name="description" content="Published research articles in journals or conferences."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon-researcher.png?5d97fb9284a4127a5f29cc49206ae5ed"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://juliepivin-bachler.github.io//publications/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Julie</span> R. Pivin-Bachler </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About me </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">Contact </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">Published research articles in journals or conferences.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IJHCI</abbr> </div> <div id="pivin-bachler_automatic_2025" class="col-sm-8"> <div class="title">Automatic Ability-Based Design (AutoABD): A Novel Framework for Accessible Technology Evaluated on Visual Abilities</div> <div class="author"> Julie R. Pivin-Bachler, Egon L. Van Den Broek, and Randy Gomez </div> <div class="periodical"> <em>International Journal of Human‚ÄìComputer Interaction</em>, Dec 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1080/10447318.2025.2596314" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Humans automatically adapt to their interlocutors, making human-human interaction universally accessible. In contrast, technology‚Äôs accessibility remains overlooked, delayed, or incomplete. To improve accessibility, many design frameworks, like Ability-Based Design (ABD), have emerged. However, to mimic human adaptation, a system must first accurately assess the interlocutors‚Äô abilities. Thus, we propose autoABD, a novel framework rendering ABD automatic via an autonomous assessment of user abilities. We test autoABD with a study including blind and sighted participants. The model‚Äôs scores, based on participants‚Äô eye gaze behavior, differed significantly between both groups (ùë°‚Å°(14)=5.15, ùëù&lt;.001), allowing the correct classification of 15/16 participants. Equivalent accessibility was demonstrated (ùëä=5.0, ùëù=0.042). Interviews confirmed technology‚Äôs lack of accessibility, highlighting the need for such a framework. autoABD‚Äôs feasibility was established for visual abilities, providing a foundation for broader application. Extending it to other abilities will enable systems to adapt to any user, thus preventing the exclusion of users with impairments.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Patterns</abbr> </div> <div id="pivin-bachler_simba_2025" class="col-sm-8"> <div class="title">SIMBA: A robust and generalizable measure of data imbalance</div> <div class="author"> Julie R. Pivin-Bachler and Egon L. Van Den Broek </div> <div class="periodical"> <em>Patterns</em>, Oct 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.patter.2025.101395" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Ranging from health to cybersecurity, real-world data are heavily imbalanced. Handling imbalance is among the formidable challenges of machine learning (ML), as it deteriorates ML‚Äôs performance, yielding biased results toward majority classes. However, finding an adequate measure to assess the impact of data imbalance is a field of research by itself. Following a review of the available imbalance measures, we introduce the status of imbalance (SIMBA), which considers data distribution and overlap, both of which are crucial to assess the impact of imbalance. SIMBA is benchmarked against seven imbalance measures on five ML models, 428 synthetic and 70 non-synthetic datasets from various domains. Resulting correlation coefficients between imbalance measures and classification performance and an analysis with 20 complexity measures prove that SIMBA consistently outperforms other measures. Overall, SIMBA accurately quantifies multiclass data imbalance and may help alleviate ML data imbalance challenges in the future.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE RO-MAN</abbr> </div> <div id="meijer_assessment_2025" class="col-sm-8"> <div class="title">Assessment of Cancer Patients‚Äô Well-Being through Electrodermal Activity</div> <div class="author"> Anneloes L. Meijer, Julie R. Pivin-Bachler, Gloria √Ålvarez Benito, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Jose Gabriel De Amores Carredano, Randy Gomez, Egon L. Van Den Broek' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In 2025 34th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</em>, Aug 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/RO-MAN63969.2025.11217689" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Hospitalized pediatric cancer patients often experience anxiety. Social robots have been proposed as intelligent monitors, embodied mediators, and embodied companions to watch over and support children with such distress. To do so, we propose to augment social robots with biosensors. ElectroDermal Activity recordings of ¬±22-hour were collected from 8 in-hospital pediatric cancer patients and 6 survivors outside the hospital, together with their diaries and an anxiety questionnaire. To optimally exploit the limited data gathered, external datasets were used to build classification models, with the best performing model achieving a cross-validated F1-score of 0.59 (SD=0.12) on the test set. The models delivered promising out-of-distribution predictions of high-arousal on the pediatric recordings. The limited number of labels available did not allow validation of all high-arousal segments, confirming the challenge of gathering reliable ground truth labels in pediatric hospitals. We suggest data collection methods to foster the further development of augmented social robots.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">SCS</abbr> </div> <div id="pivin-bachler_handling_2024" class="col-sm-8"> <div class="title">Handling sensory disabilities in a smart society: The case of a simulated social robot</div> <div class="author"> Julie Pivin-Bachler, Egon L. Van Den Broek, and Randy Gomez </div> <div class="periodical"> <em>Journal of Smart Cities and Society</em>, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3233/SCS-230019" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Billions of people live with visual and/or hearing impairments. Regrettably, their access to systems remains delayed, leaving them socially excluded. The need for universal access of next-generation systems and users‚Äô inclusion is paramount. We pose that a smart society should respond to this crucial need. Following ability-based design principles, we introduce a simulated social robot that adapts to users‚Äô sensory abilities. Its working was assessed via a Rock‚ÄìPaper‚ÄìScissors game in an Intelligent Environment (IE), using three modes: where the user is able to see and hear, only see, or only hear. With this game, two user-studies were conducted using the UMUX-LITE usability score, an expectation rating, and the gap between experience and expectation, complemented with two open questions. A repeated measures Multivariate ANalysis Of VAriance (MANOVA) on the data from study 1 unveiled an overall difference between the three modes, F ( 6 , 6 ) = 6.823, Œ∑ p 2 = .872, p = .017. Users expected applications to be harder to use with a disability, especially a visual impairment. All modes were considered accessible, with the experience exceeding expectations for the mode with a hearing impairment. In parallel, substantial variance was observed across participants and the results from the open questions suggested improvements. To reduce this variance and increase system stability, study 2 was run with an enhanced design. A repeated measures MANOVA on the data from study 2 confirmed study 1‚Äôs findings, F(6,6)=12.801, Œ∑p2=.928, p=.003. Moreover, experiences exceeded expectations in all modes and the variance among participants was substantially decreased. We conclude that IE applications managed by a social robot can be adapted to user‚Äôs sensory abilities, improving smart society‚Äôs accessibility, and, hence, reducing social exclusion.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IE2023</abbr> </div> <div id="bekaroo_one_2023" class="col-sm-8"> <div class="title">‚ÄúOne for All, All for One‚Äù. A First Step Towards Universal Access with a Social Robot</div> <div class="author"> Julie Pivin-Bachler, Randy Gomez, and Egon L. Van Den Broek </div> <div class="periodical"> <em>In Volume 32: Workshop Proceedings of the 19th International Conference on Intelligent Environments (IE2023)</em>, Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3233/AISE230031" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>The number of worldwide inhabitants suffering from visual or hearing impairments reaches billions according to the World Health Organization, making the need for universal access and inclusion in Intelligent Environments (IE) essential. An adaptive Rock-Paper-Scissors application using a simulation of the social robot Haru is presented. The accessibility of the application which covers three modes - where the user able to see and hear, only to see, or only to hear ‚Äì was verified through a user-study. A multivariate analysis of variance with repeated measures determined that the ratings from the 12 participants differed significantly across the three modes with F(6,6) = 6.823, Œ∑2p = .872, p = .017. Results show that users tend to expect applications to be harder to use when suffering from a disability, especially a visual impairment. All modes in the application were deemed acceptable in terms of usability, proving that the multimodality that comes with IE can help in promoting universal access and reducing social exclusion.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Neural Comput &amp; App</abbr> </div> <div id="harnack_quantifying_2022" class="col-sm-8"> <div class="title">Quantifying the effect of feedback frequency in interactive reinforcement learning for robotic tasks</div> <div class="author"> Daniel Harnack, Julie Pivin-Bachler, and Nicol√°s Navarro-Guerrero </div> <div class="periodical"> <em>Neural Computing and Applications</em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s00521-022-07949-0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Reinforcement learning (RL) has become widely adopted in robot control. Despite many successes, one major persisting problem can be very low data efficiency. One solution is interactive feedback, which has been shown to speed up RL considerably. As a result, there is an abundance of different strategies, which are, however, primarily tested on discrete grid-world and small scale optimal control scenarios. In the literature, there is no consensus about which feedback frequency is optimal or at which time the feedback is most beneficial. To resolve these discrepancies we isolate and quantify the effect of feedback frequency in robotic tasks with continuous state and action spaces. The experiments encompass inverse kinematics learning for robotic manipulator arms of different complexity. We show that seemingly contradictory reported phenomena occur at different complexity levels. Furthermore, our results suggest that no single ideal feedback frequency exists. Rather that feedback frequency should be changed as the agent‚Äôs proficiency in the task increases.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> ¬© Copyright 2025 Julie R. Pivin-Bachler. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>